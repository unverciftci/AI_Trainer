{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvtabcTFqrcgCkSX5lpp9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unverciftci/AI_Trainer/blob/main/AI_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4ZbWB4q64E7"
      },
      "outputs": [],
      "source": [
        "# Simple AI Trainer with Qwen3-0.6B from Scratch\n",
        "# Educational step-by-step implementation\n",
        "\n",
        "print(\"üöÄ Welcome to AI-Driven Training!\")\n",
        "print(\"We'll build everything step by step\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Step 1: Install what we need\n",
        "print(\"üì¶ Step 1: Installing packages...\")\n",
        "!pip install transformers torch matplotlib scikit-learn numpy\n",
        "\n",
        "# Step 2: Import everything\n",
        "print(\"üìö Step 2: Importing libraries...\")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "import re\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "\n",
        "# Step 3: Set up the AI Brain (Qwen3-0.6B)\n",
        "print(\"\\nüß† Step 3: Loading Qwen3-0.6B AI Brain...\")\n",
        "\n",
        "class SimpleAIBrain:\n",
        "    def __init__(self):\n",
        "        self.model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"  # Smaller variant that works well\n",
        "        print(f\"Loading {self.model_name}...\")\n",
        "\n",
        "        try:\n",
        "            # Load the AI model\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.model_name,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\"\n",
        "            )\n",
        "\n",
        "            # Set padding token\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "            print(\"‚úÖ AI Brain loaded successfully!\")\n",
        "            self.working = True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå AI Brain failed to load: {e}\")\n",
        "            print(\"üîÑ Using simple rules instead\")\n",
        "            self.working = False\n",
        "\n",
        "    def think_about_training(self, train_acc, test_acc, epoch):\n",
        "        \"\"\"Ask the AI what to do next\"\"\"\n",
        "\n",
        "        if not self.working:\n",
        "            # Simple backup rules\n",
        "            if train_acc - test_acc > 15:\n",
        "                return \"reduce_learning_rate\", \"Too much overfitting\"\n",
        "            elif train_acc < 70 and epoch > 10:\n",
        "                return \"increase_learning_rate\", \"Learning too slow\"\n",
        "            else:\n",
        "                return \"continue\", \"Looking good\"\n",
        "\n",
        "        # Create a simple question for the AI\n",
        "        question = f\"\"\"You are helping train a neural network.\n",
        "\n",
        "Current status:\n",
        "- Epoch: {epoch}\n",
        "- Training accuracy: {train_acc:.1f}%\n",
        "- Test accuracy: {test_acc:.1f}%\n",
        "\n",
        "What should I do? Choose ONE:\n",
        "1. continue (if training is going well)\n",
        "2. reduce_learning_rate (if overfitting)\n",
        "3. increase_learning_rate (if learning too slow)\n",
        "4. stop_training (if good enough)\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Ask the AI\n",
        "            inputs = self.tokenizer(question, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=30,\n",
        "                    temperature=0.3,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            # Get AI response\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "            ai_answer = response[len(question):].strip().lower()\n",
        "\n",
        "            print(f\"ü§ñ AI thinks: {ai_answer[:50]}...\")\n",
        "\n",
        "            # Extract decision from AI response\n",
        "            if \"reduce\" in ai_answer or \"lower\" in ai_answer:\n",
        "                return \"reduce_learning_rate\", \"AI suggests reducing LR\"\n",
        "            elif \"increase\" in ai_answer or \"faster\" in ai_answer:\n",
        "                return \"increase_learning_rate\", \"AI suggests increasing LR\"\n",
        "            elif \"stop\" in ai_answer or \"good enough\" in ai_answer:\n",
        "                return \"stop_training\", \"AI suggests stopping\"\n",
        "            else:\n",
        "                return \"continue\", \"AI suggests continuing\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ü§î AI thinking failed: {e}\")\n",
        "            return \"continue\", \"AI confused, continuing\"\n",
        "\n",
        "# Initialize our AI brain\n",
        "ai_brain = SimpleAIBrain()\n",
        "\n",
        "# Step 4: Create some data to learn from\n",
        "print(\"\\nüìä Step 4: Creating training data...\")\n",
        "\n",
        "# Make a fun moon-shaped dataset\n",
        "X, y = make_moons(n_samples=800, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch format\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "print(f\"‚úÖ Created dataset: {len(X_train)} training examples, {len(X_test)} test examples\")\n",
        "\n",
        "# Let's see our data\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', alpha=0.7)\n",
        "plt.title('Training Data (Moons)')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='viridis', alpha=0.7)\n",
        "plt.title('Test Data')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Create our neural network\n",
        "print(\"\\nüß† Step 5: Building neural network...\")\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # Simple 3-layer network\n",
        "        self.layer1 = nn.Linear(2, 64)    # 2 features -> 64 neurons\n",
        "        self.layer2 = nn.Linear(64, 32)   # 64 -> 32 neurons\n",
        "        self.layer3 = nn.Linear(32, 2)    # 32 -> 2 classes (moon shapes)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))    # First layer + activation\n",
        "        x = self.dropout(x)               # Prevent overfitting\n",
        "        x = torch.relu(self.layer2(x))    # Second layer + activation\n",
        "        x = self.layer3(x)                # Final layer (no activation)\n",
        "        return x\n",
        "\n",
        "# Create our model\n",
        "model = SimpleNet()\n",
        "print(f\"‚úÖ Neural network created!\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Step 6: Set up training\n",
        "print(\"\\n‚öôÔ∏è Step 6: Setting up training...\")\n",
        "\n",
        "# Training setup\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"‚úÖ Initial learning rate: {learning_rate}\")\n",
        "print(f\"‚úÖ Optimizer: Adam\")\n",
        "print(f\"‚úÖ Loss function: CrossEntropy\")\n",
        "\n",
        "# Step 7: Training functions\n",
        "print(\"\\nüîß Step 7: Creating training functions...\")\n",
        "\n",
        "def train_one_epoch(model, X_train, y_train, optimizer, loss_function):\n",
        "    \"\"\"Train the model for one epoch\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    # Forward pass\n",
        "    predictions = model(X_train)\n",
        "    loss = loss_function(predictions, y_train)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    with torch.no_grad():\n",
        "        predicted_classes = predictions.argmax(dim=1)\n",
        "        accuracy = (predicted_classes == y_train).float().mean() * 100\n",
        "\n",
        "    return loss.item(), accuracy.item()\n",
        "\n",
        "def test_model(model, X_test, y_test, loss_function):\n",
        "    \"\"\"Test the model\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test)\n",
        "        loss = loss_function(predictions, y_test)\n",
        "        predicted_classes = predictions.argmax(dim=1)\n",
        "        accuracy = (predicted_classes == y_test).float().mean() * 100\n",
        "\n",
        "    return loss.item(), accuracy.item()\n",
        "\n",
        "print(\"‚úÖ Training functions ready!\")\n",
        "\n",
        "# Step 8: The main AI-driven training loop\n",
        "print(\"\\nüöÄ Step 8: Starting AI-driven training!\")\n",
        "print(\"The AI will make decisions every 5 epochs\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Storage for results\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "losses = []\n",
        "learning_rates = []\n",
        "ai_decisions = []\n",
        "\n",
        "max_epochs = 50\n",
        "current_lr = learning_rate\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train_one_epoch(model, X_train, y_train, optimizer, loss_function)\n",
        "    test_loss, test_acc = test_model(model, X_test, y_test, loss_function)\n",
        "\n",
        "    # Store results\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "    losses.append(train_loss)\n",
        "    learning_rates.append(current_lr)\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1:2d}: Train {train_acc:5.1f}% | Test {test_acc:5.1f}% | Loss {train_loss:.4f}\")\n",
        "\n",
        "    # Let AI make decisions every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0 and epoch < max_epochs - 1:\n",
        "        print(\"\\nü§ñ AI is thinking...\")\n",
        "\n",
        "        action, reason = ai_brain.think_about_training(train_acc, test_acc, epoch + 1)\n",
        "        ai_decisions.append((epoch + 1, action, reason))\n",
        "\n",
        "        print(f\"üß† Decision: {action}\")\n",
        "        print(f\"üí≠ Reason: {reason}\")\n",
        "\n",
        "        # Apply AI decision\n",
        "        if action == \"reduce_learning_rate\":\n",
        "            current_lr = current_lr * 0.7  # Reduce by 30%\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = current_lr\n",
        "            print(f\"üìâ Learning rate ‚Üí {current_lr:.6f}\")\n",
        "\n",
        "        elif action == \"increase_learning_rate\":\n",
        "            current_lr = current_lr * 1.3  # Increase by 30%\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = current_lr\n",
        "            print(f\"üìà Learning rate ‚Üí {current_lr:.6f}\")\n",
        "\n",
        "        elif action == \"stop_training\":\n",
        "            print(\"üõë AI decided to stop training early!\")\n",
        "            break\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "print(f\"\\nüéâ Training completed!\")\n",
        "print(f\"üèÜ Final test accuracy: {test_accuracies[-1]:.1f}%\")\n",
        "\n",
        "# Step 9: Show results\n",
        "print(\"\\nüìä Step 9: Visualizing results...\")\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Plot 1: Accuracy over time\n",
        "epochs = range(1, len(train_accuracies) + 1)\n",
        "ax1.plot(epochs, train_accuracies, 'b-', label='Training', linewidth=2)\n",
        "ax1.plot(epochs, test_accuracies, 'r-', label='Test', linewidth=2)\n",
        "ax1.set_title('üéØ Accuracy Progress')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy (%)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Loss over time\n",
        "ax2.plot(epochs, losses, 'g-', linewidth=2)\n",
        "ax2.set_title('üìâ Training Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Learning rate changes\n",
        "ax3.plot(epochs, learning_rates, 'purple', linewidth=2, marker='o', markersize=3)\n",
        "ax3.set_title('ü§ñ AI Learning Rate Decisions')\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Learning Rate')\n",
        "ax3.set_yscale('log')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: AI decisions summary\n",
        "ax4.axis('off')\n",
        "ax4.set_title('üß† AI Decisions Made', fontsize=14, weight='bold')\n",
        "\n",
        "decision_text = \"\"\n",
        "for epoch, action, reason in ai_decisions[-4:]:  # Show last 4 decisions\n",
        "    emoji = {\"continue\": \"‚û°Ô∏è\", \"reduce_learning_rate\": \"üìâ\",\n",
        "             \"increase_learning_rate\": \"üìà\", \"stop_training\": \"üõë\"}.get(action, \"ü§î\")\n",
        "    decision_text += f\"Epoch {epoch}: {emoji} {action}\\n{reason}\\n\\n\"\n",
        "\n",
        "ax4.text(0.05, 0.95, decision_text, fontsize=10, transform=ax4.transAxes,\n",
        "         verticalalignment='top', fontfamily='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 10: Final summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üéä TRAINING COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"üìà Best accuracy: {max(test_accuracies):.1f}%\")\n",
        "print(f\"ü§ñ AI decisions made: {len(ai_decisions)}\")\n",
        "print(f\"üìâ Final learning rate: {current_lr:.6f}\")\n",
        "print(f\"üîÑ Started with LR: {learning_rate:.6f}\")\n",
        "\n",
        "if ai_decisions:\n",
        "    print(f\"\\nüß† AI Decision Summary:\")\n",
        "    action_counts = {}\n",
        "    for _, action, _ in ai_decisions:\n",
        "        action_counts[action] = action_counts.get(action, 0) + 1\n",
        "\n",
        "    for action, count in action_counts.items():\n",
        "        emoji = {\"continue\": \"‚û°Ô∏è\", \"reduce_learning_rate\": \"üìâ\",\n",
        "                \"increase_learning_rate\": \"üìà\", \"stop_training\": \"üõë\"}.get(action, \"ü§î\")\n",
        "        print(f\"  {emoji} {action}: {count} times\")\n",
        "\n",
        "print(\"\\nüéì What you learned:\")\n",
        "print(\"- How to load and use a small LLM (Qwen3-0.6B)\")\n",
        "print(\"- How to create a neural network from scratch\")\n",
        "print(\"- How to let AI make training decisions\")\n",
        "print(\"- How to visualize training progress\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\n‚ú® Try changing the dataset to 'circles' or 'linear' and see how the AI adapts!\")"
      ]
    }
  ]
}